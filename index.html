<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>ふわふわ ˙-˙ + camera</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #000;
    }

    #face {
      font-size: 256px;
      color: #fff;
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      white-space: nowrap;
      line-height: 0.8;
    }

    #mouth {
      display: inline-block;
      transform-origin: center center;
      transition: transform 0.05s linear;
    }

    video {
      display: none;
    }
  </style>
</head>
<body>

  <div id="face">
    <span id="left-eye">˙</span>
    <span id="mouth">-</span>
    <span id="right-eye">˙</span>
  </div>

  <video id="video" autoplay playsinline></video>

  <script>
    const face = document.getElementById('face');
    const leftEye = document.getElementById('left-eye');
    const rightEye = document.getElementById('right-eye');
    const mouth = document.getElementById('mouth');
    const video = document.getElementById('video');

    // ===== ふわふわ =====
    let angle = 0;
    function floatFace() {
      angle += 0.05;
      const y = Math.cos(angle) * 10;
      face.style.transform =
        `translate(-50%, calc(-50% + ${y}px))`;
      requestAnimationFrame(floatFace);
    }
    floatFace();

    // ===== 瞬き =====
    function blink() {
      leftEye.textContent = '¯';
      rightEye.textContent = '¯';
      setTimeout(() => {
        leftEye.textContent = currentEye;
        rightEye.textContent = currentEye;
      }, 150);
      setTimeout(blink, Math.random() * 4000 + 2000);
    }
    setTimeout(blink, 3000);

    // ===== マイク =====
    let audioCtx, analyser, dataArray;
    let smoothedVolume = 0;
    const smoothing = 0.88;

    async function initMic() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioCtx.createMediaStreamSource(stream);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 1024;
      dataArray = new Uint8Array(analyser.fftSize);
      source.connect(analyser);
      updateMouth();
    }

    function updateMouth() {
      analyser.getByteTimeDomainData(dataArray);
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) {
        const v = (dataArray[i] - 128) / 128;
        sum += v * v;
      }
      const rms = Math.sqrt(sum / dataArray.length);
      smoothedVolume =
        smoothing * smoothedVolume + (1 - smoothing) * rms;

      let scale = 0.5 + smoothedVolume * 15;
      scale = Math.min(1.8, Math.max(0.5, scale));
      mouth.style.transform = `scaleY(${scale})`;

      requestAnimationFrame(updateMouth);
    }

    // ===== カメラ & 視線追従 =====
    let detector;
    let currentEye = '˙';

    async function initCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      detector = new FaceDetector({ fastMode: true });
      detectFace();
    }

    async function detectFace() {
      if (video.readyState === 4) {
        const faces = await detector.detect(video);
        if (faces.length > 0) {
          const faceBox = faces[0].boundingBox;
          const centerX = faceBox.x + faceBox.width / 2;
          const screenCenter = video.videoWidth / 2;

          if (centerX < screenCenter - 50) {
            currentEye = '‹';
          } else if (centerX > screenCenter + 50) {
            currentEye = '›';
          } else {
            currentEye = '˙';
          }
        } else {
          currentEye = '˙';
        }

        leftEye.textContent = currentEye;
        rightEye.textContent = currentEye;
      }
      requestAnimationFrame(detectFace);
    }

    // ===== 起動（Safari対策）=====
    document.addEventListener('click', async () => {
      await initMic();
      await initCamera();
    }, { once: true });
  </script>

</body>
</html>